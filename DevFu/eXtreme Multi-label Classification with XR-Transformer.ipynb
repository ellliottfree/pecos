{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 22:52:57 URL:https://ia802308.us.archive.org/21/items/pecos-dataset/xmc-base/eurlex-4k.tar.gz [66307781/66307781] -> \"eurlex-4k.tar.gz\" [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xmc-base/eurlex-4k/X.trn.txt\n",
      "xmc-base/eurlex-4k/X.tst.txt\n",
      "xmc-base/eurlex-4k/Y.trn.npz\n",
      "xmc-base/eurlex-4k/Y.trn.txt\n",
      "xmc-base/eurlex-4k/Y.tst.npz\n",
      "xmc-base/eurlex-4k/Y.tst.txt\n",
      "xmc-base/eurlex-4k/output-items.txt\n",
      "xmc-base/eurlex-4k/tfidf-attnxml\n",
      "xmc-base/eurlex-4k/tfidf-attnxml/X.trn.npz\n",
      "xmc-base/eurlex-4k/tfidf-attnxml/X.tst.npz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATASET=\"eurlex-4k\"\n",
    "wget -nv -nc https://archive.org/download/pecos-dataset/xmc-base/${DATASET}.tar.gz\n",
    "tar --skip-old-files -zxf ${DATASET}.tar.gz \n",
    "find xmc-base/${DATASET}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from pecos.utils import smat_util, logging_util\n",
    "\n",
    "# set logging level to WARNING(1)\n",
    "# you can change this to INFO(2) or DEBUG(3) if you'd like to see more logging\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "logging_util.setup_logging_config(level=1)\n",
    "\n",
    "# load training data\n",
    "X_feat_trn = smat_util.load_matrix(\"xmc-base/eurlex-4k/tfidf-attnxml/X.trn.npz\", dtype=np.float32)\n",
    "Y_trn = smat_util.load_matrix(\"xmc-base/eurlex-4k/Y.trn.npz\", dtype=np.float32)\n",
    "\n",
    "with open(\"xmc-base/eurlex-4k/X.trn.txt\", 'r') as fin:\n",
    "    X_txt_trn = [xx.strip() for xx in fin.readlines()]\n",
    "\n",
    "# load test data\n",
    "X_feat_tst = smat_util.load_matrix(\"xmc-base/eurlex-4k/tfidf-attnxml/X.tst.npz\", dtype=np.float32)\n",
    "Y_tst = smat_util.load_matrix(\"xmc-base/eurlex-4k/Y.tst.npz\", dtype=np.float32)\n",
    "\n",
    "with open(\"xmc-base/eurlex-4k/X.tst.txt\", 'r') as fin:\n",
    "    X_txt_tst = [xx.strip() for xx in fin.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"__meta__\": {\n",
      "  \"class_fullname\": \"pecos.xmc.xtransformer.model###XTransformer.TrainParams\"\n",
      " },\n",
      " \"preliminary_indexer_params\": {\n",
      "  \"__meta__\": {\n",
      "   \"class_fullname\": \"pecos.xmc.base###HierarchicalKMeans.TrainParams\"\n",
      "  },\n",
      "  \"nr_splits\": 16,\n",
      "  \"min_codes\": 16,\n",
      "  \"max_leaf_size\": 16,\n",
      "  \"spherical\": true,\n",
      "  \"seed\": 0,\n",
      "  \"kmeans_max_iter\": 20,\n",
      "  \"threads\": -1\n",
      " },\n",
      " \"refined_indexer_params\": {\n",
      "  \"__meta__\": {\n",
      "   \"class_fullname\": \"pecos.xmc.base###HierarchicalKMeans.TrainParams\"\n",
      "  },\n",
      "  \"nr_splits\": 8,\n",
      "  \"min_codes\": null,\n",
      "  \"max_leaf_size\": 16,\n",
      "  \"spherical\": true,\n",
      "  \"seed\": 0,\n",
      "  \"kmeans_max_iter\": 20,\n",
      "  \"threads\": -1\n",
      " },\n",
      " \"matcher_params_chain\": [\n",
      "  {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.xtransformer.matcher###TransformerMatcher.TrainParams\"\n",
      "   },\n",
      "   \"model_shortcut\": \"bert-base-uncased\",\n",
      "   \"negative_sampling\": \"tfn+man\",\n",
      "   \"loss_function\": \"weighted-squared-hinge\",\n",
      "   \"bootstrap_method\": \"weighted-linear\",\n",
      "   \"lr_schedule\": \"linear\",\n",
      "   \"threshold\": 0.001,\n",
      "   \"hidden_dropout_prob\": 0.1,\n",
      "   \"batch_size\": 32,\n",
      "   \"batch_gen_workers\": 16,\n",
      "   \"max_active_matching_labels\": 1000,\n",
      "   \"max_num_labels_in_gpu\": 65536,\n",
      "   \"max_steps\": 600,\n",
      "   \"max_no_improve_cnt\": -1,\n",
      "   \"num_train_epochs\": 10,\n",
      "   \"gradient_accumulation_steps\": 1,\n",
      "   \"weight_decay\": 0.0,\n",
      "   \"max_grad_norm\": 1.0,\n",
      "   \"learning_rate\": 5e-05,\n",
      "   \"adam_epsilon\": 1e-08,\n",
      "   \"warmup_steps\": 100,\n",
      "   \"logging_steps\": 50,\n",
      "   \"save_steps\": 200,\n",
      "   \"cost_sensitive_ranker\": false,\n",
      "   \"pre_tokenize\": true,\n",
      "   \"pre_tensorize_labels\": true,\n",
      "   \"use_gpu\": true,\n",
      "   \"eval_by_true_shorlist\": false,\n",
      "   \"checkpoint_dir\": \"\",\n",
      "   \"cache_dir\": \"\",\n",
      "   \"init_model_dir\": \"\"\n",
      "  },\n",
      "  {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.xtransformer.matcher###TransformerMatcher.TrainParams\"\n",
      "   },\n",
      "   \"model_shortcut\": \"bert-base-uncased\",\n",
      "   \"negative_sampling\": \"tfn+man\",\n",
      "   \"loss_function\": \"weighted-squared-hinge\",\n",
      "   \"bootstrap_method\": \"weighted-linear\",\n",
      "   \"lr_schedule\": \"linear\",\n",
      "   \"threshold\": 0.001,\n",
      "   \"hidden_dropout_prob\": 0.1,\n",
      "   \"batch_size\": 32,\n",
      "   \"batch_gen_workers\": 16,\n",
      "   \"max_active_matching_labels\": 1000,\n",
      "   \"max_num_labels_in_gpu\": 65536,\n",
      "   \"max_steps\": 800,\n",
      "   \"max_no_improve_cnt\": -1,\n",
      "   \"num_train_epochs\": 10,\n",
      "   \"gradient_accumulation_steps\": 1,\n",
      "   \"weight_decay\": 0.0,\n",
      "   \"max_grad_norm\": 1.0,\n",
      "   \"learning_rate\": 5e-05,\n",
      "   \"adam_epsilon\": 1e-08,\n",
      "   \"warmup_steps\": 100,\n",
      "   \"logging_steps\": 50,\n",
      "   \"save_steps\": 200,\n",
      "   \"cost_sensitive_ranker\": false,\n",
      "   \"pre_tokenize\": true,\n",
      "   \"pre_tensorize_labels\": true,\n",
      "   \"use_gpu\": true,\n",
      "   \"eval_by_true_shorlist\": false,\n",
      "   \"checkpoint_dir\": \"\",\n",
      "   \"cache_dir\": \"\",\n",
      "   \"init_model_dir\": \"\"\n",
      "  },\n",
      "  {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.xtransformer.matcher###TransformerMatcher.TrainParams\"\n",
      "   },\n",
      "   \"model_shortcut\": \"bert-base-uncased\",\n",
      "   \"negative_sampling\": \"tfn+man\",\n",
      "   \"loss_function\": \"weighted-squared-hinge\",\n",
      "   \"bootstrap_method\": \"weighted-linear\",\n",
      "   \"lr_schedule\": \"linear\",\n",
      "   \"threshold\": 0.001,\n",
      "   \"hidden_dropout_prob\": 0.1,\n",
      "   \"batch_size\": 32,\n",
      "   \"batch_gen_workers\": 16,\n",
      "   \"max_active_matching_labels\": 1000,\n",
      "   \"max_num_labels_in_gpu\": 65536,\n",
      "   \"max_steps\": 1200,\n",
      "   \"max_no_improve_cnt\": -1,\n",
      "   \"num_train_epochs\": 10,\n",
      "   \"gradient_accumulation_steps\": 1,\n",
      "   \"weight_decay\": 0.0,\n",
      "   \"max_grad_norm\": 1.0,\n",
      "   \"learning_rate\": 5e-05,\n",
      "   \"adam_epsilon\": 1e-08,\n",
      "   \"warmup_steps\": 100,\n",
      "   \"logging_steps\": 50,\n",
      "   \"save_steps\": 200,\n",
      "   \"cost_sensitive_ranker\": false,\n",
      "   \"pre_tokenize\": true,\n",
      "   \"pre_tensorize_labels\": true,\n",
      "   \"use_gpu\": true,\n",
      "   \"eval_by_true_shorlist\": false,\n",
      "   \"checkpoint_dir\": \"\",\n",
      "   \"cache_dir\": \"\",\n",
      "   \"init_model_dir\": \"\"\n",
      "  }\n",
      " ],\n",
      " \"ranker_params\": {\n",
      "  \"__meta__\": {\n",
      "   \"class_fullname\": \"pecos.xmc.xlinear.model###XLinearModel.TrainParams\"\n",
      "  },\n",
      "  \"mode\": \"full-model\",\n",
      "  \"ranker_level\": 1,\n",
      "  \"nr_splits\": 16,\n",
      "  \"min_codes\": null,\n",
      "  \"shallow\": false,\n",
      "  \"rel_mode\": \"induce\",\n",
      "  \"rel_norm\": \"l1\",\n",
      "  \"hlm_args\": {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.base###HierarchicalMLModel.TrainParams\"\n",
      "   },\n",
      "   \"neg_mining_chain\": [\n",
      "    \"tfn\",\n",
      "    \"tfn\",\n",
      "    \"tfn\",\n",
      "    \"tfn+man\"\n",
      "   ],\n",
      "   \"model_chain\": [\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.TrainParams\"\n",
      "     },\n",
      "     \"threshold\": 0.001,\n",
      "     \"max_nonzeros_per_label\": null,\n",
      "     \"solver_type\": \"L2R_L2LOSS_SVC_DUAL\",\n",
      "     \"Cp\": 1.0,\n",
      "     \"Cn\": 2.0,\n",
      "     \"max_iter\": 100,\n",
      "     \"eps\": 0.1,\n",
      "     \"bias\": 1.0,\n",
      "     \"threads\": -1,\n",
      "     \"verbose\": 0,\n",
      "     \"newton_eps\": 0.01\n",
      "    },\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.TrainParams\"\n",
      "     },\n",
      "     \"threshold\": 0.001,\n",
      "     \"max_nonzeros_per_label\": null,\n",
      "     \"solver_type\": \"L2R_L2LOSS_SVC_DUAL\",\n",
      "     \"Cp\": 1.0,\n",
      "     \"Cn\": 2.0,\n",
      "     \"max_iter\": 100,\n",
      "     \"eps\": 0.1,\n",
      "     \"bias\": 1.0,\n",
      "     \"threads\": -1,\n",
      "     \"verbose\": 0,\n",
      "     \"newton_eps\": 0.01\n",
      "    },\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.TrainParams\"\n",
      "     },\n",
      "     \"threshold\": 0.001,\n",
      "     \"max_nonzeros_per_label\": null,\n",
      "     \"solver_type\": \"L2R_L2LOSS_SVC_DUAL\",\n",
      "     \"Cp\": 1.0,\n",
      "     \"Cn\": 2.0,\n",
      "     \"max_iter\": 100,\n",
      "     \"eps\": 0.1,\n",
      "     \"bias\": 1.0,\n",
      "     \"threads\": -1,\n",
      "     \"verbose\": 0,\n",
      "     \"newton_eps\": 0.01\n",
      "    },\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.TrainParams\"\n",
      "     },\n",
      "     \"threshold\": 0.001,\n",
      "     \"max_nonzeros_per_label\": null,\n",
      "     \"solver_type\": \"L2R_L2LOSS_SVC_DUAL\",\n",
      "     \"Cp\": 2.0,\n",
      "     \"Cn\": 4.0,\n",
      "     \"max_iter\": 100,\n",
      "     \"eps\": 0.1,\n",
      "     \"bias\": 1.0,\n",
      "     \"threads\": -1,\n",
      "     \"verbose\": 0,\n",
      "     \"newton_eps\": 0.01\n",
      "    }\n",
      "   ]\n",
      "  }\n",
      " },\n",
      " \"do_fine_tune\": true,\n",
      " \"only_encoder\": false,\n",
      " \"fix_clustering\": false,\n",
      " \"max_match_clusters\": 32768\n",
      "}\n",
      "{\n",
      " \"__meta__\": {\n",
      "  \"class_fullname\": \"pecos.xmc.xtransformer.model###XTransformer.PredParams\"\n",
      " },\n",
      " \"matcher_params_chain\": [\n",
      "  {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.xtransformer.matcher###TransformerMatcher.PredParams\"\n",
      "   },\n",
      "   \"only_topk\": 5,\n",
      "   \"post_processor\": \"l3-hinge\",\n",
      "   \"ensemble_method\": \"concat-only\",\n",
      "   \"truncate_length\": 128\n",
      "  },\n",
      "  {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.xtransformer.matcher###TransformerMatcher.PredParams\"\n",
      "   },\n",
      "   \"only_topk\": 5,\n",
      "   \"post_processor\": \"l3-hinge\",\n",
      "   \"ensemble_method\": \"concat-only\",\n",
      "   \"truncate_length\": 128\n",
      "  },\n",
      "  {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.xtransformer.matcher###TransformerMatcher.PredParams\"\n",
      "   },\n",
      "   \"only_topk\": 5,\n",
      "   \"post_processor\": \"l3-hinge\",\n",
      "   \"ensemble_method\": \"concat-only\",\n",
      "   \"truncate_length\": 128\n",
      "  }\n",
      " ],\n",
      " \"ranker_params\": {\n",
      "  \"__meta__\": {\n",
      "   \"class_fullname\": \"pecos.xmc.xlinear.model###XLinearModel.PredParams\"\n",
      "  },\n",
      "  \"hlm_args\": {\n",
      "   \"__meta__\": {\n",
      "    \"class_fullname\": \"pecos.xmc.base###HierarchicalMLModel.PredParams\"\n",
      "   },\n",
      "   \"model_chain\": [\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.PredParams\"\n",
      "     },\n",
      "     \"only_topk\": 75,\n",
      "     \"post_processor\": \"l3-hinge\"\n",
      "    },\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.PredParams\"\n",
      "     },\n",
      "     \"only_topk\": 75,\n",
      "     \"post_processor\": \"l3-hinge\"\n",
      "    },\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.PredParams\"\n",
      "     },\n",
      "     \"only_topk\": 100,\n",
      "     \"post_processor\": \"l3-hinge\"\n",
      "    },\n",
      "    {\n",
      "     \"__meta__\": {\n",
      "      \"class_fullname\": \"pecos.xmc.base###MLModel.PredParams\"\n",
      "     },\n",
      "     \"only_topk\": 25,\n",
      "     \"post_processor\": \"noop\"\n",
      "    }\n",
      "   ]\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from pecos.xmc.xtransformer.model import XTransformer\n",
    "\n",
    "# get XR-Transformer training params\n",
    "\n",
    "params = json.load(open(\"params.json\"))\n",
    "\n",
    "    \n",
    "eurlex4k_train_params = XTransformer.TrainParams.from_dict(params[\"train_params\"])\n",
    "eurlex4k_pred_params = XTransformer.PredParams.from_dict(params[\"pred_params\"])\n",
    "\n",
    "# you can view the detailed parameter setting via\n",
    "print(json.dumps(eurlex4k_train_params.to_dict(), indent=True))\n",
    "print(json.dumps(eurlex4k_pred_params.to_dict(), indent=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 1: XR-Linear\n",
    "Let's train a XR-Linear model on the TF-IDF features using the same hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics of XR-Linear model\n",
      "prec   = 85.05 77.98 71.30 64.77 58.78 53.15 48.02 43.61 39.94 36.84\n",
      "recall = 17.26 31.33 42.44 50.89 57.28 61.73 64.78 67.08 68.96 70.53\n"
     ]
    }
   ],
   "source": [
    "# construct label hierarchy\n",
    "from pecos.xmc import Indexer, LabelEmbeddingFactory\n",
    "cluster_chain = Indexer.gen(\n",
    "    LabelEmbeddingFactory.create(Y_trn, X_feat_trn, method=\"pifa\"),\n",
    "    train_params=eurlex4k_train_params.refined_indexer_params,\n",
    ")\n",
    "\n",
    "# train XR-Linear model\n",
    "from pecos.xmc.xlinear import XLinearModel\n",
    "xlm = XLinearModel.train(\n",
    "    X_feat_trn,\n",
    "    Y_trn,\n",
    "    C=cluster_chain,\n",
    "    train_params=eurlex4k_train_params.ranker_params,\n",
    "    pred_params=eurlex4k_pred_params.ranker_params,\n",
    ")\n",
    "\n",
    "# predict on test set with XR-Linear model\n",
    "P_xlm = xlm.predict(X_feat_tst)\n",
    "\n",
    "# compute metrics using ground truth\n",
    "metrics = smat_util.Metrics.generate(Y_tst, P_xlm)\n",
    "print(\"Evaluation metrics of XR-Linear model\")\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 2: XR-Transformer without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForXMC: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForXMC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForXMC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics of XR-Transformer (not fine-tuned)\n",
      "prec   = 84.89 78.02 71.28 64.85 58.94 53.42 48.24 43.74 39.96 36.77\n",
      "recall = 17.23 31.34 42.44 50.92 57.36 62.02 65.08 67.26 68.99 70.46\n"
     ]
    }
   ],
   "source": [
    "# define the problem\n",
    "from pecos.xmc.xtransformer.module import MLProblemWithText\n",
    "prob = MLProblemWithText(X_txt_trn, Y_trn, X_feat=X_feat_trn)\n",
    "\n",
    "# disable fine-tuning, directly use pre-trained bert model from huggingface\n",
    "eurlex4k_train_params.do_fine_tune = False\n",
    "\n",
    "# train XR-Transformer (without fine-tuning)\n",
    "# this will be slow on CPU only machine\n",
    "xrt_pretrained = XTransformer.train(\n",
    "    prob,\n",
    "    train_params=eurlex4k_train_params,\n",
    "    pred_params=eurlex4k_pred_params,\n",
    ")\n",
    "\n",
    "# predict and compute metrics\n",
    "P_xrt_pretrained = xrt_pretrained.predict(X_txt_tst, X_feat=X_feat_tst)\n",
    "metrics = smat_util.Metrics.generate(Y_tst, P_xrt_pretrained)\n",
    "print(\"Evaluation metrics of XR-Transformer (not fine-tuned)\")\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: XR-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct label hierarchy\n",
    "from pecos.xmc import Indexer, LabelEmbeddingFactory\n",
    "cluster_chain = Indexer.gen(\n",
    "    LabelEmbeddingFactory.create(Y_trn, X_feat_trn, method=\"pifa\"),\n",
    "    train_params=eurlex4k_train_params.refined_indexer_params,\n",
    ")\n",
    "\n",
    "# train XR-Linear model\n",
    "from pecos.xmc.xtransformer.module import MLProblemWithText\n",
    "prob = MLProblemWithText(X_txt_trn, Y_trn, X_feat=X_feat_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurlex4k_train_params.do_fine_tune = True\n",
    "\n",
    "xrt_fine_tuned = XTransformer.train(\n",
    "    prob,\n",
    "    \n",
    "    train_params=eurlex4k_train_params,\n",
    "    pred_params=eurlex4k_pred_params,\n",
    ")\n",
    "\n",
    "P_xrt_fine_tuned = xrt_fine_tuned.predict(X_txt_tst, X_feat=X_feat_tst)\n",
    "metrics = smat_util.Metrics.generate(Y_tst, P_xrt_fine_tuned, topk=10)\n",
    "print(\"Evaluation metrics of XR-Transformer\")\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aacf665a889f315b664388628192d2b4a328191a062d046a95d619922fddde3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
